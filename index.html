<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>ORB Feature Tool</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="./styles.css" />
</head>
<body>
  <h1 class="title">ORB Feature Tool</h1>
  <p style="color:white; margin-top:0;">
    Detects ORB (Oriented FAST and Rotated BRIEF) features in uploaded image or video frame A 
    and matches them to image B.
  </p>
  <!-- Canvas for displaying matches -->
  <div class="matches">
    <canvas id="canvasMatches" style="width:100%" hidden></canvas>
  </div>
  <!-- Main grid containing all cards (img upload, video frame extraction, matching) -->
  <div class="grid">
    <!-- Upload image A, detect ORB features and export features.json -->
    <div class="card">
      <h2>Upload Image A and Extract ORB features</h2>
      <p>Upload image, detect features & export <code>features.json</code></p>
      <div class="row">
        <input id="fileA" type="file" accept="image/*" />
        <button id="btnDetect" disabled>Detect ORB</button>
        <button id="btnDownload" disabled>Download features.json</button>
      </div>
      <!-- Extract video frame, pass to ORB detection -->
      <h2>Extract Video Frame</h2>
      <p>Upload a video file, specify frame number, and extract frame for ORB detection.</p>
      <div class="row">
        <input id="fileVideo" type="file" accept="video/*" />
        <input id="frameNumber" type="number" min="0" value="0" style="width:80px" disabled />
        <button id="btnExtractFrame" disabled>Extract Frame</button>
      </div>
      <video id="videoPreview" hidden controls style="max-width:100%;"></video>
      <canvas id="canvasFrame" hidden></canvas>
      <div class="row muted">
        nfeatures <input id="nfeatures" type="number" value="1200" min="100" max="5000" style="width:90px">
        edgeThreshold <input id="edgeThreshold" type="number" value="31" min="1" max="100" style="width:90px">
        ratio <input id="ratio" type="number" step="0.01" value="0.75" style="width:80px">
        RANSAC thresh <input id="ransac" type="number" step="0.1" value="3.0" style="width:90px">
        
      </div>
      <div style="position:relative; display:inline-block;">
        <img id="imgA" alt="Image A preview" hidden/>
        <div id="cropBox" class="crop-box" hidden>
          <div class="resize-handle" data-corner="nw"></div>
          <div class="resize-handle" data-corner="ne"></div>
          <div class="resize-handle" data-corner="sw"></div>
          <div class="resize-handle" data-corner="se"></div>
        </div>
      </div>
      <canvas id="canvasA" hidden></canvas>
      <div id="statsA" class="mono muted"></div>
    </div>

    <!-- Import JSON + match to Image B -->
    <div class="card">
      <h2>Match ORB Features to Image B</h2>
      <p>Upload image B and <code>features.json</code> to find matches.</p>
      <div class="row">
        <input id="fileJSON" type="file" accept=".json,application/json" />
        <input id="fileB" type="file" accept="image/*" />
      </div>
      <div class="row">
        <button id="btnMatch" disabled>Match</button>
      </div>
      <div style="position:relative; display:inline-block;">
        <img id="imgB" alt="Image B preview" hidden/>
        <div id="cropBoxB" class="crop-box" hidden>
          <div class="resize-handle" data-corner="nw"></div>
          <div class="resize-handle" data-corner="ne"></div>
          <div class="resize-handle" data-corner="sw"></div>
          <div class="resize-handle" data-corner="se"></div>
        </div>
      </div>
      
      <div id="statsB" class="mono muted"></div>
    </div> 
  </div>

  <!-- OpenCV.js setup -->
  <script>
    window.Module = {
      locateFile: (f) => `./opencv/${f}`,
      onRuntimeInitialized() {
        console.log('OpenCV.js ready');
        window.cvIsReady = true;           
        document.dispatchEvent(new Event('cv-ready'));
      },
      print: (txt) => console.log('[opencv]', txt),
      printErr: (txt) => console.error('[opencv-err]', txt),
      onAbort: (txt) => console.error('[opencv-abort]', txt),
    };
  </script>
  <script src="./opencv/opencv.js"></script>

  <!-- Main application script -->
  <script type="module">
    import { ORBModule } from './orb_module.js?v=20251104';
    import { VideoFrameExtractor } from './video_frame_extractor.js?v=20251104';
    import { setupCropBox } from './setup_crop_box.js?v=20251104';
    import { loadImg, matFromImageEl, cropImage } from './image_utils.js?v=20251104';

    // ------------------------------------------------
    //                   ELEMENTS 
    // ------------------------------------------------

    // ORB feature tool elements
    const el = (id) => document.getElementById(id);
    const fileA = el('fileA'), imgA = el('imgA'), canvasA = el('canvasA');
    const fileJSON = el('fileJSON'), fileB = el('fileB'), imgB = el('imgB');
    const btnDetect = el('btnDetect'), btnDownload = el('btnDownload'), btnMatch = el('btnMatch');
    const statsA = el('statsA'), statsB = el('statsB');
    const nfeatures = el('nfeatures'), ratio = el('ratio'), ransac = el('ransac'), edgeThreshold = el('edgeThreshold');
    const canvasMatches = el('canvasMatches');
    // Video frame extractor elements
    const fileVideo = el('fileVideo');
    const frameNumber = el('frameNumber');
    const btnExtractFrame = el('btnExtractFrame');
    const videoPreview = el('videoPreview');
    const canvasFrame = el('canvasFrame');

    const cropBox = document.getElementById('cropBox');
    const cropBoxB = document.getElementById('cropBoxB'); // Add this for image B

    setupCropBox(imgA, cropBox);
    setupCropBox(imgB, cropBoxB);

    // ------------------------------------------------
    //                     STATE 
    // ------------------------------------------------

    // ORB feature tool state
    let mod;
    let cvReady = false;
    let imgAReady = false;
    let imgBReady = false;
    let detectResult = null;
    let loadedJSON = null;
    // Video frame extractor state
    let videoExtractor;

    const haveFeatures = () => Boolean(loadedJSON || detectResult);

    // ------------------------------------------------
    //                     HELPERS 
    // ------------------------------------------------

    // Temporary offscreen canvas for image to Mat conversion
    const __tmpCanvas = document.createElement('canvas');
    // Context for the temporary canvas
    const __tmpCtx = __tmpCanvas.getContext('2d', { willReadFrequently: true });

    /*// Convert an HTMLImageElement to cv.Mat (CV_8UC4)
    // ______________________________________________________

    function matFromImageEl(imgEl) {
      // Get image dimensions, use natural size if available
      const w = imgEl.naturalWidth || imgEl.width;
      const h = imgEl.naturalHeight || imgEl.height;
      // Draw the <img> to an offscreen canvas and grab RGBA bytes
      __tmpCanvas.width = w; // set canvas to image width
      __tmpCanvas.height = h; // set canvas to image height
      __tmpCtx.clearRect(0, 0, w, h); // clear canvas
      __tmpCtx.drawImage(imgEl, 0, 0, w, h); // draw image to canvas
      const imageData = __tmpCtx.getImageData(0, 0, w, h); // get RGBA pixel data

      // Allocate CV_8UC4 without using 'new cv.Mat(...)'
      const mat = window.cv.Mat.zeros(h, w, window.cv.CV_8UC4);
      mat.data.set(imageData.data);   // copy RGBA buffer in
      return mat; // return CV_8UC4 Mat
    }*/

    // Get crop rectangle relative to an image element
    // ______________________________________________________

    function getCropRectGeneric(imgEl, cropBoxEl) {
      const imgRect = imgEl.getBoundingClientRect();
      const cropRect = cropBoxEl.getBoundingClientRect();
      const scaleX = imgEl.naturalWidth / imgRect.width;
      const scaleY = imgEl.naturalHeight / imgRect.height;
      return {
        x: Math.round((cropRect.left - imgRect.left) * scaleX),
        y: Math.round((cropRect.top - imgRect.top) * scaleY),
        width: Math.round(cropRect.width * scaleX),
        height: Math.round(cropRect.height * scaleY)
      };
    }

    /*// Crop an image element to a specified rectangle 
    // ______________________________________________________

    // cropRect: { x, y, width, height }
    function cropImage(imgEl, cropRect) {
      // Create a canvas to hold the cropped image
      const cropCanvas = document.createElement('canvas');
      // Set the canvas size to the crop rectangle size
      cropCanvas.width = cropRect.width; 
      cropCanvas.height = cropRect.height;
      // Get the 2D context and draw the cropped area
      const ctx = cropCanvas.getContext('2d');
      ctx.drawImage(
        imgEl, // Source image element
        cropRect.x, cropRect.y, cropRect.width, cropRect.height, // Source rectangle
        0, 0, cropRect.width, cropRect.height // Destination rectangle
      );
      // Return the cropped canvas
      return cropCanvas;
    }*/
   
    // Compatible imshow function: uses cv.imshow if available, 
    // otherwise converts Mat to ImageData and draws to canvas
    // ______________________________________________________

    function imshowCompat(canvas, mat) {
      if (window.cv.imshow) { // if the build supports imshow
        window.cv.imshow(canvas, mat); // use it directly
        return;
      }
      
      let rgba = mat; // placeholder for RGBA Mat
      
      /* 
      Convert the input Mat to RGBA format for display on a canvas. OpenCV Mats can 
      have different channel formats (RGB, RGBA). This ensures the Mat is always in 
      CV_8UC4 (RGBA) format for compatibility with ImageData and canvas.
      */

      // If the Mat is in 3-channel RGB format (CV_8UC3), convert it to 4-channel RGBA.
      if (mat.type() === window.cv.CV_8UC3) {
        rgba = new window.cv.Mat(); // Create an empty Mat for the result
        window.cv.cvtColor(mat, rgba, window.cv.COLOR_RGB2RGBA); // Convert RGB to RGBA

      // If the Mat is not already in 4-channel RGBA format (CV_8UC4), convert it.
      } else if (mat.type() !== window.cv.CV_8UC4) {
        const tmp = new window.cv.Mat(); // Temporary Mat for conversion
        window.cv.cvtColor(mat, tmp, window.cv.COLOR_RGBA2RGBA); // Convert to RGBA
        rgba = tmp; // Use the converted Mat
      
      // If the Mat is already in RGBA format, clone it to avoid modifying the original.
      } else {
        rgba = mat.clone();
      }

      // Create ImageData from the RGBA Mat data
      const imageData = new ImageData(
        new Uint8ClampedArray(rgba.data), // pixel data
        rgba.cols, rgba.rows // width and height
      );

      // Resize the canvas and put the ImageData onto it
      canvas.width = rgba.cols; // set canvas width
      canvas.height = rgba.rows; // set canvas height
      canvas.getContext('2d').putImageData(imageData, 0, 0); // draw image data
      rgba.delete(); // clean up temporary Mat if created
    }
    
    // Refresh button enabled/disabled states 
    // ______________________________________________________

    function refreshButtons() {
      // Log current states for debugging
      console.log('refreshButtons', { cvReady, imgAReady, imgBReady, haveFeatures: haveFeatures(), detectResult });
      btnDetect.disabled = !(cvReady && imgAReady); // Detect enabled if cv and imgA ready
      btnDownload.disabled = !(detectResult && detectResult.descriptors); // Download enabled if detection result with descriptors
      btnMatch.disabled = !(cvReady && imgBReady && haveFeatures()); // Match enabled if cv, imgB ready and features available
    }

    /*// Load an image file into an HTMLImageElement
    // ______________________________________________________

    function loadImg(file, imgEl, cropBox) {
      // Return a promise that resolves when the image is loaded
      return new Promise((res, rej) => {
        const r = new FileReader(); // FileReader to read the file
        r.onload = () => {
          imgEl.onload = () => {
            imgEl.hidden = false; // show image element
            // Crop box initialization
            const imgRect = imgEl.getBoundingClientRect(); // get image A bounding rect 
            cropBox.style.display = 'block'; // show crop box
            cropBox.style.left = '0px'; // align to left
            cropBox.style.top = '0px'; // align to top
            cropBox.style.width = imgRect.width + 'px'; // image width
            cropBox.style.height = imgRect.height + 'px'; // image height
            res(); 
          };
          imgEl.onerror = rej;
          imgEl.src = r.result;
        };
        r.onerror = rej; // onerror handler
        r.readAsDataURL(file); // read file as data URL
      });
    } */

    // Get crop rectangle relative to image A
    // ______________________________________________________

    function getCropRect() {
      const imgRect = imgA.getBoundingClientRect(); // get image A bounding rect
      const cropRect = cropBox.getBoundingClientRect(); // get crop box bounding rect

      // Calculate scale factors
      const scaleX = imgA.naturalWidth / imgRect.width;
      const scaleY = imgA.naturalHeight / imgRect.height;

      return { // return crop rectangle in image coordinates
        x: Math.round((cropRect.left - imgRect.left) * scaleX),
        y: Math.round((cropRect.top - imgRect.top) * scaleY),
        width: Math.round(cropRect.width * scaleX),
        height: Math.round(cropRect.height * scaleY)
      };
    }

    // Initialize ORBModule when OpenCV.js is ready
    // ______________________________________________________

    function onCvReady() {
      // Create ORBModule instance
      try {
        mod = new ORBModule(window.cv); // create ORBModule instance
        cvReady = true; // set cvReady flag
        console.log('onCvReady â†’ cvReady=true'); // log readiness
        console.log('cv.imread:', typeof window.cv.imread); // log imread availability
      // Catch any errors during initialization
      } catch (e) {
        console.error('cv init error', e);
        cvReady = false;
      }
      // Refresh button states
      refreshButtons();
    }

    // init: catch both the event *and* the already-ready case
    if (window.cvIsReady || (window.cv && (window.cv.Mat || window.cv.getBuildInformation))) {
      onCvReady();
    } else {
      document.addEventListener('cv-ready', onCvReady, { once: true });
    }

    // ------------------------------------------------
    //                     EVENTS 
    // ------------------------------------------------
      
    // Video frame extraction
    // ________________________________________________

    fileVideo.addEventListener('change', () => {
      const f = fileVideo.files?.[0];
      if (!f) return;
      const url = URL.createObjectURL(f);
      videoPreview.src = url;
      videoPreview.load();
      videoPreview.hidden = false;
      frameNumber.disabled = false;
      btnExtractFrame.disabled = false;
      videoExtractor = new VideoFrameExtractor(videoPreview, canvasFrame);
    });

    // Extract frame button
    // ________________________________________________

    btnExtractFrame.addEventListener('click', async () => {
      const frameIdx = Number(frameNumber.value) || 0;
      const fps = 25; // Can make this user configurable later
      try {
        await videoExtractor.extractFrame(frameIdx, fps);
        // Use the canvas directly for ORB detection
        const srcMat = matFromImageEl(canvasFrame);

        // Run ORB detection
        detectResult = mod.detectORB(srcMat, { nfeatures: Number(nfeatures.value) || 1200 });
        statsA.textContent =
          `A: ${detectResult.width}x${detectResult.height}\n` +
          `keypoints: ${detectResult.keypoints.length}\n` +
          `descriptors: ${detectResult.descriptors?.rows ?? 0} x ${detectResult.descriptors?.cols ?? 0}`;
        canvasA.hidden = false;
        mod.drawKeypoints(srcMat, detectResult.keypoints, canvasA);
        srcMat.delete();
        imgAReady = true;
        videoPreview.hidden = true;
        refreshButtons();
      } catch (e) {
        alert('Frame extraction failed: ' + e);
        imgAReady = false;
        refreshButtons();
      }
    });

    // Image A load
    // ________________________________________________

    fileA.addEventListener('change', async () => {
      const f = fileA.files?.[0]; // get selected file
      if (!f) return; // if no file, exit
      try { // try to load image
        await loadImg(f, imgA, cropBox); // load image into imgA element
        imgAReady = true; // set imgAReady flag
        imgA.hidden = false; // show imgA
        cropBox.hidden = false; // show crop box
        detectResult = null; // reset previous detection result
        statsA.textContent = ''; // clear stats
        canvasA.hidden = true; // hide canvasA
      } catch (e) {
        console.error('Image A preview error', e);
        imgAReady = false;
        imgA.hidden = true;
      }
      refreshButtons();
    });

    // Image B load
    // ________________________________________________

    fileB.addEventListener('change', async () => {
      const f = fileB.files?.[0];
      if (!f) return;
      try {
        await loadImg(f, imgB, cropBoxB);
        imgBReady = true;
        imgB.hidden = false;
        cropBoxB.hidden = false;
        statsB.textContent = '';
        canvasMatches.hidden = true;
      } catch (e) {
        console.error('Image B preview error', e);
        imgBReady = false;
        imgB.hidden = true;
      }
      refreshButtons();
    });

    // JSON load
    // ________________________________________________

    fileJSON.addEventListener('change', async () => {
      const f = fileJSON.files?.[0];
      if (!f) return;
      try {
        loadedJSON = JSON.parse(await f.text());
      } catch (e) {
        console.error('JSON parse error', e);
        loadedJSON = null;
      }
      refreshButtons();
    });

    // Detect ORB
    // ________________________________________________

    btnDetect.addEventListener('click', () => {
      if (!cvReady || !imgAReady) return;
      const cv = window.cv;
      // const src = cv.imread(imgA);
      const cropRect = getCropRect();
      // Crop image A according to crop box
      const croppedCanvas = cropImage(imgA, cropRect);
      // Convert cropped image to Mat
      const src = matFromImageEl(croppedCanvas);
      // Set ORB options
      const opts = { 
        nfeatures: Number(nfeatures.value) || 1200,
        edgeThreshold: Number(edgeThreshold.value) || 31
      };
      // Run detection
      try {
        // Perform ORB detection
        detectResult = mod.detectORB(src, opts);
        // Offset keypoints to match their position on the full image
        const offsetKeypoints = detectResult.keypoints.map(kp => ({
          ...kp,
          x: kp.x + cropRect.x,
          y: kp.y + cropRect.y
        }));
        // Update stats display
        statsA.textContent =
          `A: ${detectResult.width}x${detectResult.height}\n` +
          `keypoints: ${detectResult.keypoints.length}\n` +
          `descriptors: ${detectResult.descriptors?.rows ?? 0} x ${detectResult.descriptors?.cols ?? 0}`;
        // show canvasA (image with keypoints)
        canvasA.hidden = false; 
        
        // Draw keypoints on the full image
        const fullMat = matFromImageEl(imgA);
        mod.drawKeypoints(fullMat, offsetKeypoints, canvasA);
        fullMat.delete(); // clean up full image Mat
      
      } catch (e) { // catch errors
        console.error('Detect error', e);
        alert('Detect failed. See console.');
        detectResult = null;
      } finally { // cleanup
        src.delete(); // release Mat
        refreshButtons(); // refresh buttons
      }
    });

    // Download JSON
    // ________________________________________________

    btnDownload.addEventListener('click', () => {
      if (!detectResult) return;
      const json = mod.exportJSON(detectResult);
      const blob = new Blob([JSON.stringify(json, null, 2)], { type: 'application/json' });
      const a = document.createElement('a');
      a.href = URL.createObjectURL(blob);
      a.download = 'features.json';
      a.click();
      URL.revokeObjectURL(a.href);
    });

    // Match features.json to Image B
    // ________________________________________________

    btnMatch.addEventListener('click', () => {
      if (!cvReady || !imgBReady) return; // If not ready, exit
      if (!loadedJSON && !detectResult) { // No features available
        alert('Load features.json or run Detect on Image A first.');
        return;
      }
      // Get OpenCV.js reference
      const cv = window.cv;

      // Crop and process image B
      const cropRectB = getCropRectGeneric(imgB, cropBoxB);
      const croppedCanvasB = cropImage(imgB, cropRectB);
      const target = matFromImageEl(croppedCanvasB);

      // Detect ORB features on cropped image B and offset keypoints
      // Options for ORB detection
      const opts = {
        nfeatures: Number(nfeatures.value) || 1200,
        edgeThreshold: Number(edgeThreshold.value) || 31
      };
      // Detect features on image B
      const detectResultB = mod.detectORB(target, opts);
      // Offset keypoints to match their position on the full image B
      const offsetKeypointsB = detectResultB.keypoints.map(kp => ({
        ...kp,
        x: kp.x + cropRectB.x,
        y: kp.y + cropRectB.y
      }));

      // Prepare source features from loaded JSON or detected result
      const source = loadedJSON || mod.exportJSON(detectResult);
      const cropRectA = getCropRect();
      const offsetKeypointsA = source.keypoints.map(kp => ({
        ...kp,
        x: kp.x + cropRectA.x,
        y: kp.y + cropRectA.y
      }));

      try {
        // Match features
        const res = mod.matchToTarget(
          { ...source, keypoints: offsetKeypointsA },
          target,
          {
            useKnn: true,
            ratio: Number(ratio.value) || 0.75,
            ransacReprojThreshold: Number(ransac.value) || 3.0
          }
        );

        statsB.textContent =
          `B: ${target.cols}x${target.rows}\n` +
          `matches: ${res.matches.length}\n` +
          `inliers: ${res.numInliers ?? 0}\n` +
          (res.homography ? `H: [${res.homography.map(v => v.toFixed(3)).join(', ')}]` : 'H: (none)');

        if (!Array.isArray(offsetKeypointsA) || !Array.isArray(offsetKeypointsB) || !Array.isArray(res.matches)) {
          alert('No keypoints or matches found. Check your crop area and images.');
          return;
        }
        
        // Draw matches on full images using offset keypoints
        const A = matFromImageEl(imgA);
        const B = matFromImageEl(imgB);
        
        mod.drawMatches(A, B, offsetKeypointsA, offsetKeypointsB, res);
        imshowCompat(canvasMatches, mod._lastCanvasMat);

        fileB.hidden = true;
        canvasMatches.hidden = false;
        A.delete();
        B.delete();
        mod._releaseLastCanvasMat();
      } catch (e) {
        console.error('Match error', e);
        alert('Match failed. See console.');
      } finally {
        target.delete();
        refreshButtons();
      }
    });
  </script>

</body>
</html>
