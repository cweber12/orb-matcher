<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>ORB Feature Tool (Detect → Save JSON → Match)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="./styles.css" />
</head>
<body>
  <h1 class="title">ORB Feature Tool</h1>
  <p class="instructions"><strong>Instructions: </strong>Detect features on Image A → download <code>features.json</code> → load Image B + JSON → match & visualize.</p>

  <div class="grid">
    <!-- Left: Detect & Export -->
    <div class="card">
      <h2>1) Detect ORB features in Image A + export <code>features.json</code></h2>
      <div class="row">
        <input id="fileA" type="file" accept="image/*" />
        <button id="btnDetect" disabled>Detect ORB</button>
        <button id="btnDownload" disabled>Download features.json</button>
      </div>
      <div class="row muted">
        nfeatures <input id="nfeatures" type="number" value="1200" min="100" max="5000" style="width:90px">
        ratio <input id="ratio" type="number" step="0.01" value="0.75" style="width:80px">
        RANSAC thresh <input id="ransac" type="number" step="0.1" value="3.0" style="width:90px">
      </div>
      <img id="imgA" alt="Image A preview" hidden/>
      <canvas id="canvasA" hidden></canvas>
      <div id="statsA" class="mono muted"></div>
    </div>

    <div class="card">
      <h2>3) Extract frame from video</h2>
      <div class="row">
        <input id="fileVideo" type="file" accept="video/*" />
        <input id="frameNumber" type="number" min="0" value="0" style="width:80px" disabled />
        <button id="btnExtractFrame" disabled>Extract Frame</button>
      </div>
      <video id="videoPreview" hidden controls style="max-width:100%;"></video>
      <canvas id="canvasFrame" hidden></canvas>
    </div>

    <!-- Right: Import JSON + match to Image B -->
    <div class="card">
      <h2>2) Load features.json + match to Image B</h2>
      <div class="row">
        <input id="fileJSON" type="file" accept=".json,application/json" />
        <input id="fileB" type="file" accept="image/*" />
      </div>
      <div class="row">
        <button id="btnMatch" disabled>Match</button>
      </div>
      <img id="imgB" alt="Image B preview" hidden/>
      <canvas id="canvasMatches" hidden></canvas>
      <div id="statsB" class="mono muted"></div>
    </div>
  </div>

  <script>
    window.Module = {
      locateFile: (f) => `./opencv/${f}`,
      onRuntimeInitialized() {
        console.log('OpenCV.js ready');
        window.cvIsReady = true;           
        document.dispatchEvent(new Event('cv-ready'));
      },
      print: (txt) => console.log('[opencv]', txt),
      printErr: (txt) => console.error('[opencv-err]', txt),
      onAbort: (txt) => console.error('[opencv-abort]', txt),
    };
  </script>
  <script src="./opencv/opencv.js"></script>

  <script type="module">
    import { ORBModule } from './orb_module.js?v=20251104';
    import { VideoFrameExtractor } from './video_frame_extractor.js?v=20251104';


    // ---- elements ----
    // ORB feature tool elements
    const el = (id) => document.getElementById(id);
    const fileA = el('fileA'), imgA = el('imgA'), canvasA = el('canvasA');
    const fileJSON = el('fileJSON'), fileB = el('fileB'), imgB = el('imgB');
    const btnDetect = el('btnDetect'), btnDownload = el('btnDownload'), btnMatch = el('btnMatch');
    const statsA = el('statsA'), statsB = el('statsB');
    const nfeatures = el('nfeatures'), ratio = el('ratio'), ransac = el('ransac');
    const canvasMatches = el('canvasMatches');
    // Video frame extractor elements
    const fileVideo = el('fileVideo');
    const frameNumber = el('frameNumber');
    const btnExtractFrame = el('btnExtractFrame');
    const videoPreview = el('videoPreview');
    const canvasFrame = el('canvasFrame');

    // ---- state ----
    // ORB feature tool state
    let mod;
    let cvReady = false;
    let imgAReady = false;
    let imgBReady = false;
    let detectResult = null;
    let loadedJSON = null;
    // Video frame extractor state
    let videoExtractor;

    const haveFeatures = () => Boolean(loadedJSON || detectResult);

    // ---- helpers ----
    const __tmpCanvas = document.createElement('canvas');
    const __tmpCtx = __tmpCanvas.getContext('2d', { willReadFrequently: true });

    function matFromImageEl(imgEl) {
      const w = imgEl.naturalWidth || imgEl.width;
      const h = imgEl.naturalHeight || imgEl.height;

      // Draw the <img> to an offscreen canvas and grab RGBA bytes
      __tmpCanvas.width = w;
      __tmpCanvas.height = h;
      __tmpCtx.clearRect(0, 0, w, h);
      __tmpCtx.drawImage(imgEl, 0, 0, w, h);
      const imageData = __tmpCtx.getImageData(0, 0, w, h);

      // Allocate CV_8UC4 without using 'new cv.Mat(...)'
      const mat = window.cv.Mat.zeros(h, w, window.cv.CV_8UC4);
      mat.data.set(imageData.data);   // copy RGBA buffer in
      return mat;
    }

    function imshowCompat(canvas, mat) {
      if (window.cv.imshow) { // if your build has it, use it
        window.cv.imshow(canvas, mat);
        return;
      }
      // Ensure RGBA, then paint with putImageData
      let rgba = mat;
      if (mat.type() === window.cv.CV_8UC3) {
        rgba = new window.cv.Mat();
        window.cv.cvtColor(mat, rgba, window.cv.COLOR_RGB2RGBA);
      } else if (mat.type() !== window.cv.CV_8UC4) {
        const tmp = new window.cv.Mat();
        window.cv.cvtColor(mat, tmp, window.cv.COLOR_RGBA2RGBA);
        rgba = tmp;
      } else {
        rgba = mat.clone();
      }
      const imageData = new ImageData(
        new Uint8ClampedArray(rgba.data),
        rgba.cols, rgba.rows
      );
      canvas.width = rgba.cols;
      canvas.height = rgba.rows;
      canvas.getContext('2d').putImageData(imageData, 0, 0);
      rgba.delete();
    }
    
    function refreshButtons() {
      console.log('refreshButtons', { cvReady, imgAReady, imgBReady, haveFeatures: haveFeatures(), detectResult });
      btnDetect.disabled = !(cvReady && imgAReady);
      btnDownload.disabled = !(detectResult && detectResult.descriptors);
      btnMatch.disabled = !(cvReady && imgBReady && haveFeatures());
    }

    function loadImg(file, imgEl) {
      return new Promise((res, rej) => {
        const r = new FileReader();
        r.onload = () => { imgEl.onload = () => res(); imgEl.onerror = rej; imgEl.src = r.result; };
        r.onerror = rej;
        r.readAsDataURL(file);
      });
    }

    function onCvReady() {
      try {
        mod = new ORBModule(window.cv);
        cvReady = true;
        console.log('onCvReady → cvReady=true');
        console.log('cv.imread:', typeof window.cv.imread);
      } catch (e) {
        console.error('cv init error', e);
        cvReady = false;
      }
      refreshButtons();
    }

    // init: catch both the event *and* the already-ready case
    if (window.cvIsReady || (window.cv && (window.cv.Mat || window.cv.getBuildInformation))) {
      onCvReady();
    } else {
      document.addEventListener('cv-ready', onCvReady, { once: true });
    }

    // ---- events ----

    // Enable frame input and button when video is loaded
    fileVideo.addEventListener('change', () => {
      const f = fileVideo.files?.[0];
      if (!f) return;
      const url = URL.createObjectURL(f);
      videoPreview.src = url;
      videoPreview.load();
      videoPreview.hidden = false;
      frameNumber.disabled = false;
      btnExtractFrame.disabled = false;
      videoExtractor = new VideoFrameExtractor(videoPreview, canvasFrame);
    });

    // Extract frame button
    btnExtractFrame.addEventListener('click', async () => {
      const frameIdx = Number(frameNumber.value) || 0;
      const fps = 25; // Can make this user configurable later
      try {
        await videoExtractor.extractFrame(frameIdx, fps);
        // Use the canvas directly for ORB detection
        const srcMat = matFromImageEl(canvasFrame);

        // Run ORB detection
        detectResult = mod.detectORB(srcMat, { nfeatures: Number(nfeatures.value) || 1200 });
        statsA.textContent =
          `A: ${detectResult.width}x${detectResult.height}\n` +
          `keypoints: ${detectResult.keypoints.length}\n` +
          `descriptors: ${detectResult.descriptors?.rows ?? 0} x ${detectResult.descriptors?.cols ?? 0}`;
        canvasA.hidden = false;
        mod.drawKeypoints(srcMat, detectResult.keypoints, canvasA);
        srcMat.delete();
        imgAReady = true;
        refreshButtons();
      } catch (e) {
        alert('Frame extraction failed: ' + e);
        imgAReady = false;
        refreshButtons();
      }
    });

    // Image A load
    fileA.addEventListener('change', async () => {
      const f = fileA.files?.[0];
      if (!f) return;
      try {
        await loadImg(f, imgA);
        imgAReady = true;
        imgA.hidden = false;
        detectResult = null;
        statsA.textContent = '';
        canvasA.hidden = true;
      } catch (e) {
        console.error('Image A preview error', e);
        imgAReady = false;
        imgA.hidden = true;
      }
      refreshButtons();
    });

    // Image B load
    fileB.addEventListener('change', async () => {
      const f = fileB.files?.[0];
      if (!f) return;
      try {
        await loadImg(f, imgB);
        imgBReady = true;
        imgB.hidden = false;
        statsB.textContent = '';
        canvasMatches.hidden = true;
      } catch (e) {
        console.error('Image B preview error', e);
        imgBReady = false;
        imgB.hidden = true;
      }
      refreshButtons();
    });

    // JSON load
    fileJSON.addEventListener('change', async () => {
      const f = fileJSON.files?.[0];
      if (!f) return;
      try {
        loadedJSON = JSON.parse(await f.text());
      } catch (e) {
        console.error('JSON parse error', e);
        loadedJSON = null;
      }
      refreshButtons();
    });

    // Detect ORB
    btnDetect.addEventListener('click', () => {
      if (!cvReady || !imgAReady) return;
      const cv = window.cv;
      // const src = cv.imread(imgA);
      const src = matFromImageEl(imgA); 
      const opts = { nfeatures: Number(nfeatures.value) || 1200 };
      try {
        detectResult = mod.detectORB(src, opts);
        statsA.textContent =
          `A: ${detectResult.width}x${detectResult.height}\n` +
          `keypoints: ${detectResult.keypoints.length}\n` +
          `descriptors: ${detectResult.descriptors?.rows ?? 0} x ${detectResult.descriptors?.cols ?? 0}`;
        canvasA.hidden = false;
        mod.drawKeypoints(src, detectResult.keypoints, canvasA);
      } catch (e) {
        console.error('Detect error', e);
        alert('Detect failed. See console.');
        detectResult = null;
      } finally {
        src.delete();
        refreshButtons();
      }
    });

    // Download JSON
    btnDownload.addEventListener('click', () => {
      if (!detectResult) return;
      const json = mod.exportJSON(detectResult);
      const blob = new Blob([JSON.stringify(json, null, 2)], { type: 'application/json' });
      const a = document.createElement('a');
      a.href = URL.createObjectURL(blob);
      a.download = 'features.json';
      a.click();
      URL.revokeObjectURL(a.href);
    });

    // Match
    btnMatch.addEventListener('click', () => {
      if (!cvReady || !imgBReady) return;
      if (!loadedJSON && !detectResult) { alert('Load features.json or run Detect on Image A first.'); return; }
      const cv = window.cv;
      // const target = cv.imread(imgB);
      const target = matFromImageEl(imgB); // short term fix for imread issues
      const source = loadedJSON || mod.exportJSON(detectResult);
      try {
        const res = mod.matchToTarget(source, target, {
          useKnn: true,
          ratio: Number(ratio.value) || 0.75,
          ransacReprojThreshold: Number(ransac.value) || 3.0
        });
        statsB.textContent =
          `B: ${target.cols}x${target.rows}\n` +
          `matches: ${res.matches.length}\n` +
          `inliers: ${res.numInliers ?? 0}\n` +
          (res.homography ? `H: [${res.homography.map(v => v.toFixed(3)).join(', ')}]` : 'H: (none)');
        // const A = cv.imread(imgA);
        const A = matFromImageEl(imgA); // short term fix for imread issues
        mod.drawMatches(A, target, source.keypoints, res);
        // cv.imshow(canvasMatches, mod._lastCanvasMat);
        imshowCompat(canvasMatches, mod._lastCanvasMat); // custom imshow
        canvasMatches.hidden = false;
        A.delete();
        mod._releaseLastCanvasMat();
      } catch (e) {
        console.error('Match error', e);
        alert('Match failed. See console.');
      } finally {
        target.delete();
        refreshButtons();
      }
    });
  </script>


</body>
</html>
