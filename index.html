<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>ORB Feature Tool</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="./styles.css" />
</head>
<body>
  <h1 class="title">ORB Feature Tool</h1>
  <p style="color:white; margin-top:0;">
    Detects ORB (Oriented FAST and Rotated BRIEF) features in uploaded image or video frame A 
    and matches them to image B.
  </p>
  <!-- Main grid containing all cards (img upload, video frame extraction, matching) -->
  <div class="grid">
    <!-- Upload image A, detect ORB features and export features.json -->
    <div class="card">
      <h2>Upload Image A and Extract ORB features</h2>
      <p>Upload image, detect features & export <code>features.json</code></p>
      <div class="row">
        <input id="fileA" type="file" accept="image/*" />
        <button id="btnDetect" disabled>Detect ORB</button>
        <button id="btnDownload" disabled>Download features.json</button>
      </div>
      <div class="row muted">
        nfeatures <input id="nfeatures" type="number" value="1200" min="100" max="5000" style="width:90px">
        edgeThreshold <input id="edgeThreshold" type="number" value="31" min="1" max="100" style="width:90px">
        ratio <input id="ratio" type="number" step="0.01" value="0.75" style="width:80px">
        RANSAC thresh <input id="ransac" type="number" step="0.1" value="3.0" style="width:90px">
        
      </div>
      <div style="position:relative; display:inline-block;">
        <img id="imgA" alt="Image A preview" hidden/>
        <div id="cropBox"
             style="position:absolute; border:2px dashed #00f; background:rgba(0,0,255,0.1); cursor:move; display:none;"></div>
      </div>
      <canvas id="canvasA" hidden></canvas>
      <div id="statsA" class="mono muted"></div>
    </div>

    <!-- Extract video frame, pass to ORB detection (prev card) -->
    <div class="card">
      <h2>Extract Video Frame</h2>
      <p>Upload a video file, specify frame number, and extract frame for ORB detection.</p>
      <div class="row">
        <input id="fileVideo" type="file" accept="video/*" />
        <input id="frameNumber" type="number" min="0" value="0" style="width:80px" disabled />
        <button id="btnExtractFrame" disabled>Extract Frame</button>
      </div>
      <video id="videoPreview" hidden controls style="max-width:100%;"></video>
      <canvas id="canvasFrame" hidden></canvas>
    </div>

    <!-- Import JSON + match to Image B -->
    <div class="card">
      <h2>Match ORB Features to Image B</h2>
      <p>Upload image B and <code>features.json</code> to find matches.</p>
      <div class="row">
        <input id="fileJSON" type="file" accept=".json,application/json" />
        <input id="fileB" type="file" accept="image/*" />
      </div>
      <div class="row">
        <button id="btnMatch" disabled>Match</button>
      </div>
      <img id="imgB" alt="Image B preview" hidden/>
      <canvas id="canvasMatches" style="width:100%" hidden></canvas>
      <div id="statsB" class="mono muted"></div>
    </div>
    
  </div>

  <!-- OpenCV.js setup -->
  <script>
    window.Module = {
      locateFile: (f) => `./opencv/${f}`,
      onRuntimeInitialized() {
        console.log('OpenCV.js ready');
        window.cvIsReady = true;           
        document.dispatchEvent(new Event('cv-ready'));
      },
      print: (txt) => console.log('[opencv]', txt),
      printErr: (txt) => console.error('[opencv-err]', txt),
      onAbort: (txt) => console.error('[opencv-abort]', txt),
    };
  </script>
  <script src="./opencv/opencv.js"></script>

  <!-- Main application script -->
  <script type="module">
    import { ORBModule } from './orb_module.js?v=20251104';
    import { VideoFrameExtractor } from './video_frame_extractor.js?v=20251104';

    // ------------------------------------------------
    //                   ELEMENTS 
    // ------------------------------------------------

    // ORB feature tool elements
    const el = (id) => document.getElementById(id);
    const fileA = el('fileA'), imgA = el('imgA'), canvasA = el('canvasA');
    const fileJSON = el('fileJSON'), fileB = el('fileB'), imgB = el('imgB');
    const btnDetect = el('btnDetect'), btnDownload = el('btnDownload'), btnMatch = el('btnMatch');
    const statsA = el('statsA'), statsB = el('statsB');
    const nfeatures = el('nfeatures'), ratio = el('ratio'), ransac = el('ransac'), edgeThreshold = el('edgeThreshold');
    const canvasMatches = el('canvasMatches');
    // Video frame extractor elements
    const fileVideo = el('fileVideo');
    const frameNumber = el('frameNumber');
    const btnExtractFrame = el('btnExtractFrame');
    const videoPreview = el('videoPreview');
    const canvasFrame = el('canvasFrame');

    // ------------------------------------------------
    //                     STATE 
    // ------------------------------------------------

    // ORB feature tool state
    let mod;
    let cvReady = false;
    let imgAReady = false;
    let imgBReady = false;
    let detectResult = null;
    let loadedJSON = null;
    // Video frame extractor state
    let videoExtractor;

    const haveFeatures = () => Boolean(loadedJSON || detectResult);

    // ------------------------------------------------
    //                     HELPERS 
    // ------------------------------------------------

    // Temporary offscreen canvas for image to Mat conversion
    const __tmpCanvas = document.createElement('canvas');
    // Context for the temporary canvas
    const __tmpCtx = __tmpCanvas.getContext('2d', { willReadFrequently: true });

    // Convert an HTMLImageElement to cv.Mat (CV_8UC4)
    // -----------------------------------------------
    function matFromImageEl(imgEl) {
      // Get image dimensions, use natural size if available
      const w = imgEl.naturalWidth || imgEl.width;
      const h = imgEl.naturalHeight || imgEl.height;
      // Draw the <img> to an offscreen canvas and grab RGBA bytes
      __tmpCanvas.width = w; // set canvas to image width
      __tmpCanvas.height = h; // set canvas to image height
      __tmpCtx.clearRect(0, 0, w, h); // clear canvas
      __tmpCtx.drawImage(imgEl, 0, 0, w, h); // draw image to canvas
      const imageData = __tmpCtx.getImageData(0, 0, w, h); // get RGBA pixel data

      // Allocate CV_8UC4 without using 'new cv.Mat(...)'
      const mat = window.cv.Mat.zeros(h, w, window.cv.CV_8UC4);
      mat.data.set(imageData.data);   // copy RGBA buffer in
      return mat; // return CV_8UC4 Mat
    }

    // Crop an image element to a specified rectangle 
    // -----------------------------------------------
    // cropRect: { x, y, width, height }
    function cropImage(imgEl, cropRect) {
      // Create a canvas to hold the cropped image
      const cropCanvas = document.createElement('canvas');
      // Set the canvas size to the crop rectangle size
      cropCanvas.width = cropRect.width; 
      cropCanvas.height = cropRect.height;
      // Get the 2D context and draw the cropped area
      const ctx = cropCanvas.getContext('2d');
      ctx.drawImage(
        imgEl, // Source image element
        cropRect.x, cropRect.y, cropRect.width, cropRect.height, // Source rectangle
        0, 0, cropRect.width, cropRect.height // Destination rectangle
      );
      // Return the cropped canvas
      return cropCanvas;
    }
   
    // Compatible imshow function: uses cv.imshow if available, 
    // otherwise converts Mat to ImageData and draws to canvas
    // -----------------------------------------------
    function imshowCompat(canvas, mat) {
      if (window.cv.imshow) { // if the build supports imshow
        window.cv.imshow(canvas, mat); // use it directly
        return;
      }
      
      let rgba = mat; // placeholder for RGBA Mat
      
      /* 
      Convert the input Mat to RGBA format for display on a canvas. OpenCV Mats can 
      have different channel formats (RGB, RGBA). This ensures the Mat is always in 
      CV_8UC4 (RGBA) format for compatibility with ImageData and canvas.
      */

      // If the Mat is in 3-channel RGB format (CV_8UC3), convert it to 4-channel RGBA.
      if (mat.type() === window.cv.CV_8UC3) {
        rgba = new window.cv.Mat(); // Create an empty Mat for the result
        window.cv.cvtColor(mat, rgba, window.cv.COLOR_RGB2RGBA); // Convert RGB to RGBA

      // If the Mat is not already in 4-channel RGBA format (CV_8UC4), convert it.
      } else if (mat.type() !== window.cv.CV_8UC4) {
        const tmp = new window.cv.Mat(); // Temporary Mat for conversion
        window.cv.cvtColor(mat, tmp, window.cv.COLOR_RGBA2RGBA); // Convert to RGBA
        rgba = tmp; // Use the converted Mat
      
      // If the Mat is already in RGBA format, clone it to avoid modifying the original.
      } else {
        rgba = mat.clone();
      }

      // Create ImageData from the RGBA Mat data
      const imageData = new ImageData(
        new Uint8ClampedArray(rgba.data), // pixel data
        rgba.cols, rgba.rows // width and height
      );

      // Resize the canvas and put the ImageData onto it
      canvas.width = rgba.cols; // set canvas width
      canvas.height = rgba.rows; // set canvas height
      canvas.getContext('2d').putImageData(imageData, 0, 0); // draw image data
      rgba.delete(); // clean up temporary Mat if created
    }
    
    // Refresh button enabled/disabled states 
    // ------------------------------------------------
    function refreshButtons() {
      // Log current states for debugging
      console.log('refreshButtons', { cvReady, imgAReady, imgBReady, haveFeatures: haveFeatures(), detectResult });
      btnDetect.disabled = !(cvReady && imgAReady); // Detect enabled if cv and imgA ready
      btnDownload.disabled = !(detectResult && detectResult.descriptors); // Download enabled if detection result with descriptors
      btnMatch.disabled = !(cvReady && imgBReady && haveFeatures()); // Match enabled if cv, imgB ready and features available
    }

    // Load an image file into an HTMLImageElement
    // ------------------------------------------------
    function loadImg(file, imgEl) {
      // Return a promise that resolves when the image is loaded
      return new Promise((res, rej) => {
        const r = new FileReader(); // FileReader to read the file
        r.onload = () => { imgEl.onload = () => res(); imgEl.onerror = rej; imgEl.src = r.result; }; // onload handler
        r.onerror = rej; // onerror handler
        r.readAsDataURL(file); // read file as data URL
      });
    }

    // Get crop rectangle relative to image A
    // ------------------------------------------------
    function getCropRect() {
      const imgRect = imgA.getBoundingClientRect(); // get image A bounding rect
      const cropRect = cropBox.getBoundingClientRect(); // get crop box bounding rect
      // calculate crop rectangle relative to image A
      return {
        x: cropRect.left - imgRect.left, // relative x position
        y: cropRect.top - imgRect.top, // relative y position
        width: cropRect.width, // relative width
        height: cropRect.height // relative height
      };
    }

    // ------------------------------------------------
    //           INITIALIZATION
    // ------------------------------------------------

    // Initialize ORBModule when OpenCV.js is ready
    // ------------------------------------------------
    function onCvReady() {
      // Create ORBModule instance
      try {
        mod = new ORBModule(window.cv); // create ORBModule instance
        cvReady = true; // set cvReady flag
        console.log('onCvReady â†’ cvReady=true'); // log readiness
        console.log('cv.imread:', typeof window.cv.imread); // log imread availability
      // Catch any errors during initialization
      } catch (e) {
        console.error('cv init error', e);
        cvReady = false;
      }
      // Refresh button states
      refreshButtons();
    }

    // init: catch both the event *and* the already-ready case
    if (window.cvIsReady || (window.cv && (window.cv.Mat || window.cv.getBuildInformation))) {
      onCvReady();
    } else {
      document.addEventListener('cv-ready', onCvReady, { once: true });
    }

    // ------------------------------------------------
    //                     EVENTS 
    // ------------------------------------------------

    // ________________________________________________
    // CROP BOX DRAGGING
    
    // Define drag behavior for crop box
    const cropBox = document.getElementById('cropBox');
    let isDragging = false, startX, startY, startLeft, startTop;

    // Mouse down on crop box to start dragging
    // -----------------------------------------------
    cropBox.addEventListener('mousedown', (e) => {
      isDragging = true; // set dragging flag
      startX = e.clientX; // record start X
      startY = e.clientY; // record start Y
      startLeft = parseInt(cropBox.style.left, 10); // record start left position
      startTop = parseInt(cropBox.style.top, 10); // record start top position
      e.preventDefault(); // prevent default behavior
    });

    // Mouse move to drag crop box
    // -----------------------------------------------
    document.addEventListener('mousemove', (e) => {
      if (!isDragging) return; // if not dragging, exit
      const dx = e.clientX - startX; // calculate delta X
      const dy = e.clientY - startY; // calculate delta Y
      cropBox.style.left = `${startLeft + dx}px`; // update left position
      cropBox.style.top = `${startTop + dy}px`; // update top position
    });

    // Mouse up to stop dragging
    // -----------------------------------------------
    document.addEventListener('mouseup', () => {
      isDragging = false; // clear dragging flag
    });
    
    // END CROP BOX DRAGGING
    // ________________________________________________
    
    // Enable frame input and button when video is loaded
    fileVideo.addEventListener('change', () => {
      const f = fileVideo.files?.[0];
      if (!f) return;
      const url = URL.createObjectURL(f);
      videoPreview.src = url;
      videoPreview.load();
      videoPreview.hidden = false;
      frameNumber.disabled = false;
      btnExtractFrame.disabled = false;
      videoExtractor = new VideoFrameExtractor(videoPreview, canvasFrame);
    });

    // Extract frame button
    btnExtractFrame.addEventListener('click', async () => {
      const frameIdx = Number(frameNumber.value) || 0;
      const fps = 25; // Can make this user configurable later
      try {
        await videoExtractor.extractFrame(frameIdx, fps);
        // Use the canvas directly for ORB detection
        const srcMat = matFromImageEl(canvasFrame);

        // Run ORB detection
        detectResult = mod.detectORB(srcMat, { nfeatures: Number(nfeatures.value) || 1200 });
        statsA.textContent =
          `A: ${detectResult.width}x${detectResult.height}\n` +
          `keypoints: ${detectResult.keypoints.length}\n` +
          `descriptors: ${detectResult.descriptors?.rows ?? 0} x ${detectResult.descriptors?.cols ?? 0}`;
        canvasA.hidden = false;
        mod.drawKeypoints(srcMat, detectResult.keypoints, canvasA);
        srcMat.delete();
        imgAReady = true;
        refreshButtons();
      } catch (e) {
        alert('Frame extraction failed: ' + e);
        imgAReady = false;
        refreshButtons();
      }
    });

    // Image A load
    fileA.addEventListener('change', async () => {
      const f = fileA.files?.[0]; // get selected file
      if (!f) return; // if no file, exit
      try { // try to load image
        await loadImg(f, imgA); // load image into imgA element
        imgAReady = true; // set imgAReady flag
        imgA.hidden = false; // show imgA element
        detectResult = null; // reset previous detection result
        statsA.textContent = ''; // clear stats
        canvasA.hidden = true; // hide canvasA

        // Show crop box
        cropBox.style.display = 'block';
        cropBox.style.left = '50px';
        cropBox.style.top = '50px';
        cropBox.style.width = '100px';
        cropBox.style.height = '100px';

      } catch (e) {
        console.error('Image A preview error', e);
        imgAReady = false;
        imgA.hidden = true;
      }
      refreshButtons();
    });

    // Image B load
    fileB.addEventListener('change', async () => {
      const f = fileB.files?.[0];
      if (!f) return;
      try {
        await loadImg(f, imgB);
        imgBReady = true;
        imgB.hidden = false;
        statsB.textContent = '';
        canvasMatches.hidden = true;
      } catch (e) {
        console.error('Image B preview error', e);
        imgBReady = false;
        imgB.hidden = true;
      }
      refreshButtons();
    });

    // JSON load
    fileJSON.addEventListener('change', async () => {
      const f = fileJSON.files?.[0];
      if (!f) return;
      try {
        loadedJSON = JSON.parse(await f.text());
      } catch (e) {
        console.error('JSON parse error', e);
        loadedJSON = null;
      }
      refreshButtons();
    });

    // Detect ORB
    btnDetect.addEventListener('click', () => {
      if (!cvReady || !imgAReady) return;
      const cv = window.cv;
      // const src = cv.imread(imgA);
      const src = matFromImageEl(imgA); 
      const opts = { 
        nfeatures: Number(nfeatures.value) || 1200,
        edgeThreshold: Number(edgeThreshold.value) || 31
      };
      try {
        detectResult = mod.detectORB(src, opts);
        statsA.textContent =
          `A: ${detectResult.width}x${detectResult.height}\n` +
          `keypoints: ${detectResult.keypoints.length}\n` +
          `descriptors: ${detectResult.descriptors?.rows ?? 0} x ${detectResult.descriptors?.cols ?? 0}`;
        canvasA.hidden = false;
        mod.drawKeypoints(src, detectResult.keypoints, canvasA);
      } catch (e) {
        console.error('Detect error', e);
        alert('Detect failed. See console.');
        detectResult = null;
      } finally {
        src.delete();
        refreshButtons();
      }
    });

    // Download JSON
    btnDownload.addEventListener('click', () => {
      if (!detectResult) return;
      const json = mod.exportJSON(detectResult);
      const blob = new Blob([JSON.stringify(json, null, 2)], { type: 'application/json' });
      const a = document.createElement('a');
      a.href = URL.createObjectURL(blob);
      a.download = 'features.json';
      a.click();
      URL.revokeObjectURL(a.href);
    });

    // Match
    btnMatch.addEventListener('click', () => {
      if (!cvReady || !imgBReady) return;
      if (!loadedJSON && !detectResult) { alert('Load features.json or run Detect on Image A first.'); return; }
      const cv = window.cv;
      // const target = cv.imread(imgB);
      const target = matFromImageEl(imgB); // short term fix for imread issues
      const source = loadedJSON || mod.exportJSON(detectResult);
      try {
        const res = mod.matchToTarget(source, target, {
          useKnn: true,
          ratio: Number(ratio.value) || 0.75,
          ransacReprojThreshold: Number(ransac.value) || 3.0
        });
        statsB.textContent =
          `B: ${target.cols}x${target.rows}\n` +
          `matches: ${res.matches.length}\n` +
          `inliers: ${res.numInliers ?? 0}\n` +
          (res.homography ? `H: [${res.homography.map(v => v.toFixed(3)).join(', ')}]` : 'H: (none)');
        // const A = cv.imread(imgA);
        const A = matFromImageEl(imgA); // short term fix for imread issues
        mod.drawMatches(A, target, source.keypoints, res);
        // cv.imshow(canvasMatches, mod._lastCanvasMat);
        imshowCompat(canvasMatches, mod._lastCanvasMat); // custom imshow
        fileB.hidden = true;
        canvasMatches.hidden = false;
        A.delete();
        mod._releaseLastCanvasMat();
      } catch (e) {
        console.error('Match error', e);
        alert('Match failed. See console.');
      } finally {
        target.delete();
        refreshButtons();
      }
    });
  </script>

</body>
</html>
